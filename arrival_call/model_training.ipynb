{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_tcn import TCN  # 来自 pytorch-tcn 库\n",
    "from livelossplot import PlotLosses\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de6b960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "666bb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElevatorCallsDataset(Dataset):\n",
    "    def __init__(self, df, input_len=60, gap = 30 ,output_window=60):\n",
    "        \"\"\"\n",
    "        df: pandas DataFrame with time series data (按时间排序，频次例如每秒／每分钟)\n",
    "        input_len: 用多少时间步 (window length) 作为输入\n",
    "        gap: 输入和输出之间的时间间隔（例如30表示预测输入和输出之间有30个秒的间隔）\n",
    "        output_window: 预测多少步之后 (例如 60 表示预测下一分钟)\n",
    "        feature_cols: list of feature列名 (包含楼层 call & direction one-hot + optional 时间特征)\n",
    "        target_cols: list of target 列名 (未来是否有 call）\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.input_len = input_len\n",
    "        self.gap = gap\n",
    "        self.output_window = output_window\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.input_len - self.gap - self.output_window + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.iloc[idx : idx + self.input_len,:].values.astype(np.float32)\n",
    "        output_window = self.df.iloc[idx + self.input_len + self.gap - 1 : idx + self.input_len + self.gap + self.output_window - 1,1:]\n",
    "        # 如果有任何一个时间步有 call，则标记为 1\n",
    "        y = (output_window.sum(axis=0) > 0).astype(np.float32).values\n",
    "        \n",
    "        # 转成 tensor\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "class ElevatorTCNModel(nn.Module):\n",
    "    def __init__(self, input_channels, output_size, num_channels=[64, 64, 64], kernel_size=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.tcn = TCN(num_inputs=input_channels,\n",
    "                       num_channels=num_channels,\n",
    "                       kernel_size=kernel_size,\n",
    "                       dropout=dropout,\n",
    "                       causal=True)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_channels)  \n",
    "        # 但 PyTorch-TCN 默认期望 (batch, channels, length)，因此需要转置\n",
    "        x = x.transpose(1, 2)  # -> (batch, input_channels, seq_len)\n",
    "        y = self.tcn(x)        # -> (batch, num_channels[-1], seq_len)\n",
    "        # 取最后一个 time step’s feature map\n",
    "        out = self.linear(y[:, :, -1])  # -> (batch, output_size)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43ffe507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2055880 entries, 0 to 2055879\n",
      "Data columns (total 21 columns):\n",
      " #   Column     Dtype\n",
      "---  ------     -----\n",
      " 0   timestamp  int64\n",
      " 1   0_Up       int64\n",
      " 2   0_Down     int64\n",
      " 3   1_Up       int64\n",
      " 4   2_Up       int64\n",
      " 5   2_Down     int64\n",
      " 6   3_Up       int64\n",
      " 7   3_Down     int64\n",
      " 8   4_Up       int64\n",
      " 9   4_Down     int64\n",
      " 10  5_Up       int64\n",
      " 11  5_Down     int64\n",
      " 12  6_Up       int64\n",
      " 13  6_Down     int64\n",
      " 14  7_Up       int64\n",
      " 15  7_Down     int64\n",
      " 16  8_Up       int64\n",
      " 17  8_Down     int64\n",
      " 18  9_Up       int64\n",
      " 19  9_Down     int64\n",
      " 20  10_Down    int64\n",
      "dtypes: int64(21)\n",
      "memory usage: 329.4 MB\n"
     ]
    }
   ],
   "source": [
    "trainset = pd.read_csv('trainset.csv')  # 示例加载数据\n",
    "trainset['timestamp'] = pd.to_datetime(trainset['timestamp'])\n",
    "\n",
    "# timestamp to unix timestamp\n",
    "trainset['timestamp'] = trainset['timestamp'].astype(np.int64) // 10**9\n",
    "trainset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "878f1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv('testset.csv')\n",
    "testset['timestamp'] = pd.to_datetime(testset['timestamp'])\n",
    "\n",
    "    # timestamp to unix timestamp\n",
    "testset['timestamp'] = testset['timestamp'].astype(np.int64) // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0448c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1235afc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     23\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[0;32m     24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(logits, y_batch)\n",
      "File \u001b[1;32md:\\Develop\\miniconda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32md:\\Develop\\miniconda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Develop\\miniconda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Develop\\miniconda\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m, in \u001b[0;36mElevatorCallsDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     output_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgap \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m : idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgap \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_window \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# 如果有任何一个时间步有 call，则标记为 1\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = ElevatorCallsDataset(trainset, input_len=60, gap=30, output_window=60)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ElevatorCallsDataset(testset, input_len=60, gap=30, output_window=60)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model = ElevatorTCNModel(input_channels=len(trainset.columns), output_size=len(trainset.columns)-1)\n",
    "model.to(device)\n",
    "\n",
    "pos_count = torch.from_numpy(trainset.iloc[:, 1:].sum().to_numpy()).float()\n",
    "neg_count = trainset.shape[0] - pos_count\n",
    "pos_weight = neg_count / (pos_count + 1e-6)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "\n",
    "plot = PlotLosses()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        epoch_accuracy += (preds == y_batch).float().mean().item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_accuracy = 0.0\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            logits = model(x_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            test_loss += loss.item()\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            test_accuracy += (preds == y_batch).float().mean().item()\n",
    "            \n",
    "    \n",
    "    epoch_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    epoch_accuracy /= len(train_loader)\n",
    "    test_accuracy /= len(test_loader)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    logs = {'loss': epoch_loss, 'val_loss': test_loss, 'accuracy': epoch_accuracy, 'val_accuracy': test_accuracy}\n",
    "    plot.update(logs)\n",
    "    plot.send()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "used_time = end_time - start_time\n",
    "print(f\"Training completed in {used_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967796f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'elevator_tcn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a1b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "headers = {\"Authorization\": \"eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOjc1NTE1MywidXVpZCI6IjQwZDZlNjVhM2VmZWJlYjQiLCJpc19hZG1pbiI6ZmFsc2UsImJhY2tzdGFnZV9yb2xlIjoiIiwiaXNfc3VwZXJfYWRtaW4iOmZhbHNlLCJzdWJfbmFtZSI6IiIsInRlbmFudCI6ImF1dG9kbCIsInVwayI6IiJ9.2oepLBMnnfPJVGzSGo2RI33NsnMmAZh1LCbL14AZEaMa55d55UM2C8CJioPiwoOjbfO8SQlZdVTiwky6GeljWg\"}\n",
    "resp = requests.post(\"https://www.autodl.com/api/v1/wechat/message/send\",\n",
    "                     json={\n",
    "                         \"title\": f\"train_done, used time {used_time}, loss {test_loss}\",\n",
    "                         \"name\": \"facial keypoint\",\n",
    "                         \"content\": \"facial keypoint cnn training done\"\n",
    "                     }, headers = headers)\n",
    "print(resp.content.decode())\n",
    "\n",
    "time.sleep(30)\n",
    "\n",
    "os.system(\"/usr/bin/shutdown\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
